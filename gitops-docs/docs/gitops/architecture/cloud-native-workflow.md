# Cloud-Native Deployment Workflow

## Overview

This document describes the **cloud-native deployment workflow** for Super Fortnight microservices, implementing industry-leading GitOps practices with a **Helm + Kustomize hybrid** approach.

## Architecture Principles

### Design Goals

âœ… **Team Autonomy** - Each team owns their service completely  
âœ… **DRY Principle** - Eliminate duplication through templating  
âœ… **GitOps Native** - Git as single source of truth  
âœ… **Environment Parity** - Consistent deployments across environments  
âœ… **Selective Adoption** - Teams control when to adopt platform updates

### Three-Tier Architecture

```mermaid
---
title: Three Tier Deployment Architecture
config:
  theme: forest
  look: classic
  layout: elk
---
graph LR
  subgraph "**Starter Charts**"
    baseChart@{icon: "logos:helm", label: "Starter Service Chart"}
  end

  subgraph "**Feature Team Services**"
    chart1@{icon: "logos:helm",label: "Chart-Service-I" }
    chart2@{icon: "logos:helm",label: "Chart-Service-II" }
    service1@{icon: "logos:github-icon",label: "Chart-Service-I" }
    service2@{icon: "logos:github-icon",label: "Chart-Service-II" }
    baseChart -->|initialize| chart1
    baseChart -->|initialize| chart2
    chart1 --> |manages| service1
    chart2 -->|manages| service2
  end

  subgraph "**Kubernetes Clusters**"
    dev@{icon: "logos:kubernetes", label: "Dev Cluster", shape:"hexagon"}
    staging@{icon: "logos:kubernetes", label: "Staging Cluster", shape:"hexagon"}
    production@{icon: "logos:kubernetes", label: "Production Cluster", shape:"hexagon"}
  end

  subgraph "**Platform GitOps**"
    gitops@{icon: "logos:argo",label:"GitOps Repository"}
    service1 -->|monitors| gitops
    service2 -->|monitors| gitops
    gitops -->|deploys| dev
    gitops -->|deploys| production
    gitops -->|deploys| staging
  end

```

## Repository Structure

### 1. Platform Chart Repository (sf-helm-registry)

**Owner**: Platform Team  
**Purpose**: Centralized Helm chart templates  
**GitHub**: https://github.com/ashutosh-18k92/sf-helm-registry.git

```
sf-helm-registry/
â”œâ”€â”€ charts
â”‚   â”œâ”€â”€ api                                 # api chart
â”‚   â”‚   â”œâ”€â”€ Chart.yaml
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ templates
â”‚   â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ _helpers.tpl
â”‚   â”‚   â”‚   â”œâ”€â”€ hpa.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ NOTES.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ serviceAccount.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â”‚   â””â”€â”€ tests
â”‚   â”‚   â”‚       â””â”€â”€ test-connection.yaml
â”‚   â”‚   â”œâ”€â”€ values.schema.json
â”‚   â”‚   â””â”€â”€ values.yaml
â”‚   â””â”€â”€ worker                                # worker chart
â”‚       â”œâ”€â”€ Chart.yaml
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ templates
â”‚       â”‚   â”œâ”€â”€ deployment.yaml
â”‚       â”‚   â”œâ”€â”€ _helpers.tpl
â”‚       â”‚   â”œâ”€â”€ hpa.yaml
â”‚       â”‚   â”œâ”€â”€ ingress.yaml
â”‚       â”‚   â”œâ”€â”€ NOTES.txt
â”‚       â”‚   â”œâ”€â”€ serviceAccount.yaml
â”‚       â”‚   â”œâ”€â”€ service.yaml
â”‚       â”‚   â””â”€â”€ tests
â”‚       â”‚       â””â”€â”€ test-connection.yaml
â”‚       â”œâ”€â”€ values.schema.json
â”‚       â””â”€â”€ values.yaml
â””â”€â”€ README.md
```

**Features**:

- Production-ready templates
- Affinity rules for HA
- HPA with CPU/memory targets
- Istio service mesh integration
- Standardized labels and annotations

### 2. Team Service Repository (aggregator-service)

**Owner**: Aggregator Team  
**Purpose**: Application code + deployment configuration  
**GitHub**: https://github.com/ashutosh-18k92/aggregator-service.git

```
aggregator-service/
â”œâ”€â”€ charts
â”‚   â”œâ”€â”€ aggregator
â”‚   â”‚   â”œâ”€â”€ Chart.yaml
â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ templates
â”‚   â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ _helpers.tpl
â”‚   â”‚   â”‚   â”œâ”€â”€ hpa.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ NOTES.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ serviceAccount.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â”‚   â””â”€â”€ tests
â”‚   â”‚   â”‚       â””â”€â”€ test-connection.yaml
â”‚   â”‚   â”œâ”€â”€ values.schema.json
â”‚   â”‚   â””â”€â”€ values.yaml
â”‚   â””â”€â”€ ct.yaml
â”œâ”€â”€ deploy
â”‚   â”œâ”€â”€ environments
â”‚   â”‚   â”œâ”€â”€ development.yaml
â”‚   â”‚   â””â”€â”€ production.todo
â”‚   â””â”€â”€ overlays
â”‚       â”œâ”€â”€ development
â”‚       â”‚   â”œâ”€â”€ kustomization.yaml
â”‚       â”‚   â”œâ”€â”€ patches
â”‚       â”‚   â”‚   â”œâ”€â”€ configmap.yaml
â”‚       â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚       â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚       â”‚   â”‚   â””â”€â”€ ingress.yaml
â”‚       â”‚   â””â”€â”€ values.yaml
â”‚       â””â”€â”€ production
â”‚           â”œâ”€â”€ kustomization.yaml
â”‚           â”œâ”€â”€ patches
â”‚           â”‚   â”œâ”€â”€ deployment-affinity.yaml
â”‚           â”‚   â”œâ”€â”€ hpa-scaling.yaml
â”‚           â”‚   â””â”€â”€ production-resources.yaml
â”‚           â””â”€â”€ values.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ package.json
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ pnpm-lock.yaml
â”œâ”€â”€ README.md
â”œâ”€â”€ src
â”‚   â””â”€â”€ index.ts
â””â”€â”€ tsconfig.json
```

### 3. GitOps Repository (gitops-v2)

**Owner**: Platform Team  
**Purpose**: ArgoCD application definitions

```
gitops-v2/
â””â”€â”€ services/
    â”œâ”€â”€ aggregator-service.yaml      # ArgoCD App
    â””â”€â”€ README.md
```

## Workflow Deep Dive

### Base Values

The `charts/aggregator/values.yaml` file contains the base configuration:

### Testing the Chart

```bash
# Render chart with default values
helm template aggregator ./charts/aggregator

# Render with development values
helm template aggregator ./charts/aggregator \
  -f deploy/overlays/development/values.yaml

# Validate chart
helm lint ./charts/aggregator
```

## Deployment

### Environment Overlays

Each environment has its own overlay in `deploy/overlays/`:

```
deploy/overlays/
â””â”€â”€ [environment]/
     â”œâ”€â”€ kustomization.yaml    # References aggregator chart
     â”œâ”€â”€ values.yaml           # env-specific values
     â””â”€â”€ patches/              # env-specific patches
```

### Example Development Overlay

**File**: `deploy/overlays/development/kustomization.yaml`

```yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

helmCharts:
  - name: aggregator
    repo: https://ashutosh-18k92.github.io/aggregator-service
    releaseName: aggregator-service
    namespace: super-fortnight-dev
    valuesFile: values.yaml
    version: v0.1.0
    includeCRDs: false
```

**File**: `deploy/overlays/development/values.yaml`

```yaml
app:
  name: aggregator-service
  component: api
  partOf: superfortnight

environment: development

image:
  tag: "dev-latest"
  pullPolicy: Always

env:
  LOG_LEVEL: "debug"
  NODE_ENV: "development"

autoscaling:
  enabled: false

resources:
  requests:
    memory: "128Mi"
    cpu: "100m"
```

### Environment Overlays

**Production Patches**:

1. **Affinity** - Node and zone spreading for HA
2. **HPA** - 5-20 replicas with CPU/memory targets
3. **Resources** - Increased limits for production load

**Development**:

- 1 replica
- Debug logging
- Minimal resources
- Fast iteration

### ArgoCD Integration

**File**: `gitops-v2/services/aggregator-appset.yaml`

```yaml
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: aggregator-service
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "100"
spec:
  goTemplate: true
  generators:
    - git:
        repoURL: https://github.com/ashutosh-18k92/aggregator-service.git
        revision: main
        files:
          - path: "deploy/environments/*.yaml"

  template:
    metadata:
      name: "aggregator-service-{{.env}}"
      namespace: argocd
      finalizers:
        - resources-finalizer.argocd.argoproj.io

    spec:
      project: default

      # Single source: Kustomize overlay (includes Helm chart + patches)
      source:
        repoURL: https://github.com/ashutosh-18k92/aggregator-service.git
        targetRevision: "{{.targetRevision}}"
        path: deploy/overlays/{{.env}}
        kustomize: {} # Uses global --enable-helm from argocd-cm

      destination:
        server: https://kubernetes.default.svc
        namespace: "{{.namespace}}"

      syncPolicy:
        automated:
          enabled: true
          prune: true
          selfHeal: true

      ignoreDifferences:
        - group: apps
          kind: Deployment
          jsonPointers:
            - /spec/replicas
```

## Team Workflows

### Scenario 1: Application Development

```bash
# Clone team repository
git clone https://github.com/your-org/aggregator-service.git
cd aggregator-service

# Develop feature
vim src/index.ts
npm run dev

# Update deployment config (same PR!)
vim deploy/base/values.yaml
# Update image tag

# Commit both code and config
git add src/ deploy/
git commit -m "Add feature X with deployment config"
git push

# ArgoCD auto-syncs to cluster
```

**Benefits**:

- âœ… Code and deployment in single PR
- âœ… Atomic changes
- âœ… Easy rollback
- âœ… Complete team ownership

### Scenario 2: Should we allow Platform Starter Chart Updates?

**Benefits**:

- âœ… Team controls timing
- âœ… Can test before deploying
- âœ… No forced updates
- âœ… Gradual rollout across teams

### Scenario 3: Custom Configuration (Patches)

> ArgoCD runs into **drift** issue with patches when there is an overlapping configuration between overlays and patches. We should only apply patches for which there exists no configuration in the chart templates. For the configurations that templates are designed to substitute must only be overriden with overlays and not by patches.

```bash
# Add production-specific feature flag
cd deploy/overlays/production

cat > patches/feature-flag.yaml <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: aggregator-api-v1
spec:
  template:
    spec:
      containers:
        - name: api
          env:
            - name: ENABLE_CACHING
              value: "true"
EOF

vim kustomization.yaml
# declare patch (among other patches)
patches:
  - target: # narrow down the target to patch (best practice)
      kind: Deployment
      name: aggregator-api-v1
    path: patches/feature-flag.yaml


git commit -m "Enable caching in production"
git push
```

**Benefits**:

- âœ… Environment-specific config
- âœ… No base chart modification
- âœ… Preserved across updates
- âœ… Clear separation of concerns

## Platform Team Workflows

### Releasing Base Chart Updates

```bash
# Clone platform chart repository
git clone https://github.com/ashutosh-18k92/sf-helm-registry.git
cd sf-helm-registry/api

# Add new feature
vim templates/deployment.yaml
# Add Prometheus annotations

# Update version
vim Chart.yaml
# version: 0.1.0 â†’ 0.2.0

# Test
helm lint .
helm template test . --dry-run

# Commit and tag
git add .
git commit -m "v0.2.0: Add Prometheus monitoring annotations"
git tag v0.2.0
git push origin main --tags

# Announce to teams
# Teams adopt when ready!
```

### Announcing Updates

```markdown
ğŸ“¢ **API Chart v0.2.0 Released**

**New Features**:

- Prometheus monitoring annotations
- Improved health check defaults
- Updated resource recommendations

**Breaking Changes**: None

**Upgrade**: Update `version: 0.2.0` in your `deploy/base/kustomization.yaml`

**Documentation**: See CHANGELOG.md
```

## Best Practices

### âœ… DO

**Platform Team**:

- Use semantic versioning for chart releases
- Document changes in CHANGELOG
- Test with real services before releasing
- Announce updates to feature teams
- Maintain backward compatibility

**Feature Teams**:

- Pin specific chart versions
- Keep service values minimal
- Use overlays for environment differences
- Test with `kustomize build` before pushing
- Review platform updates before adopting

### âŒ DON'T

**Platform Team**:

- Don't force teams to upgrade
- Don't break compatibility without major version bump
- Don't add service-specific logic to base chart

**Feature Teams**:

- Don't use `latest` for chart version
- Don't duplicate base chart logic
- Don't hardcode values in patches
- Don't skip testing before deployment

## Benefits Achieved

### Team Autonomy

- âœ… Complete ownership of service
- âœ… Single repository for code + deployment
- âœ… Control over platform updates
- âœ… Independent release cycles

### DRY Principle

- âœ… Base chart eliminates duplication
- âœ… Service values: 30 lines (vs 200+ before)
- âœ… Shared templates across all services
- âœ… Consistent patterns

### GitOps Excellence

- âœ… Git as single source of truth
- âœ… Declarative configuration
- âœ… Automated sync via ArgoCD
- âœ… Easy rollback capability
- âœ… Audit trail via Git history

### Environment Management

- âœ… Base values for all environments
- âœ… Environment-specific overlays
- âœ… Production patches for HA
- âœ… Consistent deployment patterns

## Architecture Comparison

| Aspect             | Traditional      | Our Approach                  |
| ------------------ | ---------------- | ----------------------------- |
| **Manifests**      | Plain YAML       | Helm + Kustomize              |
| **Repository**     | Central monorepo | Team-owned per service        |
| **Duplication**    | High             | None (DRY)                    |
| **Team Control**   | Limited          | Complete                      |
| **Updates**        | Forced           | Selective adoption            |
| **Environments**   | Separate files   | Overlays with patches         |
| **Base Templates** | None             | GitHub repository             |
| **Values**         | Hardcoded        | Templated + minimal overrides |

## Verification

### Test Kustomize Build

```bash
cd aggregator-service
kustomize build deploy/overlays/production
```

### Deploy to Cluster

```bash
# Apply ArgoCD application
kubectl apply -f gitops-v2/services/aggregator-service.yaml

# Verify sync status
argocd app get aggregator-service

# Check deployed resources
kubectl get all -n super-fortnight -l app.kubernetes.io/name=aggregator-api-v1
```

## Summary

This workflow represents **best-in-class cloud-native practices**:

âœ… **Team Autonomy** - Complete ownership  
âœ… **DRY Principle** - Zero duplication  
âœ… **GitOps Native** - Git as source of truth  
âœ… **Selective Adoption** - Teams control updates  
âœ… **Environment Parity** - Consistent deployments  
âœ… **Production Ready** - HA, scaling, monitoring

**Result**: Scalable, maintainable, team-friendly deployment workflow! ğŸš€
